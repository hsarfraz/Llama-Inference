version: "3.8"
 
services:
  tgi:
    image: ghcr.io/huggingface/text-generation-inference
    container_name: infer
    ports:
      - "8080:80" 
    networks:
      - tracenet
    volumes: 
      - /media/ms/DATA/models:/data
      - /tmp:/tmp             
    environment:
      - MODEL_ID=/data/Llama-2-7B-32K-Instruct-GPTQ
      - NUM_SHARD=1
      - QUANTIZE=gptq
      - SHM-SIZE=1g
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
  web:
      build:
        context: ./webserver
      container_name: webserve
      depends_on:
        - "tgi"        
      ports:
        - "80:8003"   
      networks:
        - tracenet              
      volumes:
          - .:/app              
networks:
   tracenet: 
